{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:02:31.487527Z",
     "start_time": "2018-01-30T16:02:30.716941Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "\n",
    "import custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Elevated-plus maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T18:01:55.719816Z",
     "start_time": "2018-01-30T18:01:55.707833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behav_source = 'D:/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_EPM/PNOC_Behavior/*.xlsx'\n",
    "trace_source = 'D:/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_EPM/PNOC_Traces/*.txt'\n",
    "del_epm = 'EPM/del_epm.csv'\n",
    "\n",
    "h5_outfile = 'data/epm.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:04:23.664327Z",
     "start_time": "2018-01-30T16:04:23.657406Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "bin_size = 200\n",
    "exp_dur = 600000\n",
    "n_cores = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:33:00.422959Z",
     "start_time": "2018-01-30T16:32:24.498416Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "def import_behav(filename):\n",
    "    _, subj, epoch = os.path.splitext(os.path.basename(filename))[0].split('_')\n",
    "    data = custom.etho_extract(filename)\n",
    "    data.index = data.index * 1000\n",
    "    \n",
    "    return (subj, epoch), data\n",
    "\n",
    "behav_files = glob.glob(behav_source)\n",
    "p = mp.Pool(processes=n_cores)\n",
    "exps, behav_import = zip(*p.map(import_behav, behav_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:33:04.214114Z",
     "start_time": "2018-01-30T16:33:04.204344Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct for extra 10 s at beginning of behavioral data\n",
    "for data in behav_import:\n",
    "    data.index -= 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:19.971600Z",
     "start_time": "2018-01-30T16:39:16.866493Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe from all animals\n",
    "\n",
    "ts = np.arange(0, exp_dur, bin_size)\n",
    "subjs = [x for x, _ in exps]\n",
    "\n",
    "dfs = {}  # Dictionary to store DataFrame from each animal\n",
    "for subj, data in zip(subjs, behav_import):\n",
    "    data_ds = custom.resample(data, data.index, ts, method=np.nanmean)\n",
    "    ds_df = pd.DataFrame(data_ds, columns=data.columns, index=ts)\n",
    "    ds_df.columns.names = ['feature']\n",
    "    ds_df.index.names = ['timestamp']\n",
    "    dfs[subj] = ds_df\n",
    "\n",
    "# Create DataFrame for all data\n",
    "behav_df = pd.concat(dfs, axis=1, names=['subject', 'feature'])\n",
    "behav_df = behav_df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import calcium imaging data\n",
    "Each session is 1499 or 1500 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:26.191746Z",
     "start_time": "2018-01-30T16:39:26.186765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "frame_dur = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:32.779315Z",
     "start_time": "2018-01-30T16:39:31.432162Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace_files = glob.glob(trace_source)\n",
    "\n",
    "trace_import = {\n",
    "    os.path.basename(f).split('_')[1]: pd.DataFrame(np.loadtxt(f, delimiter=',').T)\n",
    "    for f in trace_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:49.035813Z",
     "start_time": "2018-01-30T16:39:48.922971Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "\n",
    "neural_df = pd.concat(trace_import, axis=1)\n",
    "neural_df.columns.names = ['subject', 'neuron']\n",
    "neural_df.index = np.arange(0, exp_dur, frame_dur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:17:21.273714Z",
     "start_time": "2017-11-03T23:17:22.069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = np.arange(0, exp_dur, bin_size)\n",
    "data_ds = custom.resample(neural_df_orig, neural_df.index, ts, method=np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:40:52.905082Z",
     "start_time": "2018-01-30T16:40:52.832597Z"
    }
   },
   "outputs": [],
   "source": [
    "neural_df = pd.DataFrame(neural_df, columns=neural_df.columns, index=ts)\n",
    "neural_df.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T17:57:56.341579Z",
     "start_time": "2018-01-30T17:57:56.276357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "\n",
    "# Import files with cells to delete\n",
    "delete_import = pd.read_csv(del_epm, delimiter=',')\n",
    "delete_import -= 1\n",
    "delete_import = delete_import.unstack().dropna()\n",
    "delete_import = delete_import.reset_index(level=-1, drop=True).astype(int)\n",
    "delete_import = delete_import.reset_index()\n",
    "delete_import.columns = ['subject', 'neuron']\n",
    "\n",
    "# Delete cells\n",
    "neural_df_cleaned = neural_df.drop([tuple(x) for x in delete_import.as_matrix()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T17:57:59.080731Z",
     "start_time": "2018-01-30T17:57:58.905753Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(h5_outfile) as hf:\n",
    "    hf['behav'] = behav_df\n",
    "    hf['neural'] = neural_df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='headfixed'></a>\n",
    "# Headfixed exposure\n",
    "Create behavioral file with `pupilize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:06:13.066793Z",
     "start_time": "2017-11-05T17:06:13.047357Z"
    }
   },
   "outputs": [],
   "source": [
    "frame_dur = 200\n",
    "threshold = 225\n",
    "\n",
    "# Input files\n",
    "del_tmt = os.path.join(data_dir, '2P Data/del_hf-tmt.csv')\n",
    "raw_data_tmt = os.path.join(data_dir, '2P Data/PNOC_Behavior')\n",
    "ca_files = glob.glob(os.path.join(data_dir, '2P Data/PNOC_HFTMT/PNOC_Traces/*.txt')\n",
    "\n",
    "# Output files\n",
    "h5_out = os.path.join(data_dir, '2P Data/headfixed.h5')\n",
    "h5_out_tmt = os.path.join(data_dir, 'We PNOC-ing/Latest PNOC Data/hf-data-tmt.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:39:22.711014Z",
     "start_time": "2017-11-04T19:25:16.959008Z"
    }
   },
   "outputs": [],
   "source": [
    "!\"organize_behav.py\" -n 7 -t \"$treshold\" -b \"$frame_dur\" -o \"$h5_out_tmt\" \"$raw_data_tmt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:02.257839Z",
     "start_time": "2017-11-04T19:45:01.406727Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "\n",
    "# Read individual dataset files\n",
    "with pd.HDFStore(h5_out) as hf, pd.HDFStore(h5_out_tmt, 'r') as hf_tmt:\n",
    "    hf['behav'] = hf_tmt['behav']\n",
    "    hf['behav'] = hf['behav'].rename(index={'ctrl': 'h2o', 'stim': 'odor'})\n",
    "\n",
    "    hf['behav'] = df_behav\n",
    "\n",
    "# Remove individual dataset files\n",
    "os.remove(h5_out_tmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T16:52:23.150758Z",
     "start_time": "2017-11-05T16:52:23.144337Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "frames_per_epoch = 1505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check frame counts on new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T16:52:24.417508Z",
     "start_time": "2017-11-05T16:52:24.370900Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of frames for each epoch\n",
    "frame_ct = {\n",
    "    'J31_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J50_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J51_TMT_A_P1': [1504, 1504, 1504],\n",
    "    'J52_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J53_TMT_B_P1': [1505, 1505, 1505],\n",
    "    'J55_TMT_B_P1': [1505, 1505, 1505],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:07:02.782260Z",
     "start_time": "2017-11-05T17:06:43.155449Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "ca_import = {\n",
    "    tuple(os.path.splitext(os.path.basename(f))[0].split('_')): np.loadtxt(f, delimiter=',')\n",
    "    for f in ca_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:09:13.003162Z",
     "start_time": "2017-11-05T17:09:12.362874Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe for calcium traces\n",
    "\n",
    "# Create new dictionary with key for each neuron\n",
    "ca_data = {}\n",
    "for exp, exp_data in ca_import.iteritems():\n",
    "    n_cells, n_frames = exp_data.shape\n",
    "    exp_id = frame_ct['_'.join(exp[1:])]\n",
    "    \n",
    "    epoch_split = np.split(exp_data, np.cumsum(exp_id)[:2], axis=1)\n",
    "    epoch_split_new = [\n",
    "        np.concatenate([epoch, np.nan * np.zeros((n_cells, frames_per_epoch - nf))], axis=1)\n",
    "        for epoch, nf in zip(epoch_split, exp_id)\n",
    "    ]\n",
    "    traces_new = np.concatenate(epoch_split_new, axis=1)\n",
    "    \n",
    "    for n, cell_data in enumerate(traces_new):\n",
    "        ca_data[exp + (n, )] = cell_data\n",
    "\n",
    "# Create dataframe\n",
    "neural_df = pd.DataFrame(ca_data)\n",
    "\n",
    "# Format columns\n",
    "col_names = ['data type', 'subject', 'experiment', 'order', 'plane', 'neuron']\n",
    "col_order = ['data type', 'experiment', 'subject', 'plane', 'order', 'neuron']\n",
    "neural_df.columns.names = col_names\n",
    "neural_df = neural_df.reorder_levels(col_order, axis=1)\n",
    "neural_df = neural_df.sort_index(axis=1)\n",
    "\n",
    "# Format index\n",
    "neural_df.index = pd.MultiIndex.from_product(\n",
    "    [['base', 'h2o', 'odor'], np.arange(frames_per_epoch) * frame_period],\n",
    "    names=['epoch', 'time']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:21.248370Z",
     "start_time": "2017-11-04T19:45:20.941730Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "\n",
    "delete_import = pd.read_csv(del_tmt, delimiter=',')\n",
    "delete_import.columns = pd.MultiIndex.from_tuples(\n",
    "    [[x[0], ] + x[1].split('_') for x in delete_import.columns]\n",
    ")\n",
    "\n",
    "# Cells to delete from TMT dataset\n",
    "to_delete = [\n",
    "    col + (int(x) - 1, )\n",
    "    for col in delete_import for x in delete_import[col]\n",
    "    if not np.isnan(x)\n",
    "]\n",
    "\n",
    "temp = neural_df.T.reset_index(['data type', 'order']).T\n",
    "temp = temp.drop(to_delete, axis=1)\n",
    "temp = temp.T.set_index(['data type', 'order'], append=True).T\n",
    "temp = temp.reorder_levels(col_order, axis=1)\n",
    "temp = temp.sort_index(axis=1)\n",
    "neural_df = temp.dropna(axis=0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:21.710265Z",
     "start_time": "2017-11-04T19:45:21.566832Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(h5_out) as hf:\n",
    "    hf['neural'] = neural_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "228px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "739px",
    "left": "0px",
    "right": "1317px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
