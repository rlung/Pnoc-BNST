{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Homecage-odor-exposure\" data-toc-modified-id=\"Homecage-odor-exposure-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Homecage odor exposure</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import data</a></div><div class=\"lev3 toc-item\"><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Parameters</a></div><div class=\"lev3 toc-item\"><a href=\"#Import-behavior\" data-toc-modified-id=\"Import-behavior-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Import behavior</a></div><div class=\"lev3 toc-item\"><a href=\"#Import-calcium-imaging-data\" data-toc-modified-id=\"Import-calcium-imaging-data-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Import calcium imaging data</a></div><div class=\"lev2 toc-item\"><a href=\"#Clean-up-imaging-data\" data-toc-modified-id=\"Clean-up-imaging-data-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Clean up imaging data</a></div><div class=\"lev2 toc-item\"><a href=\"#Register-neurons\" data-toc-modified-id=\"Register-neurons-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Register neurons</a></div><div class=\"lev2 toc-item\"><a href=\"#Save-data\" data-toc-modified-id=\"Save-data-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Save data</a></div><div class=\"lev1 toc-item\"><a href=\"#Elevated-plus-maze\" data-toc-modified-id=\"Elevated-plus-maze-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Elevated-plus maze</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import data</a></div><div class=\"lev3 toc-item\"><a href=\"#Import-behavioral-data\" data-toc-modified-id=\"Import-behavioral-data-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Import behavioral data</a></div><div class=\"lev3 toc-item\"><a href=\"#Downsample-data\" data-toc-modified-id=\"Downsample-data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Downsample data</a></div><div class=\"lev3 toc-item\"><a href=\"#Import-calcium-imaging-data\" data-toc-modified-id=\"Import-calcium-imaging-data-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Import calcium imaging data</a></div><div class=\"lev3 toc-item\"><a href=\"#Downsample-data-(if-necessary)\" data-toc-modified-id=\"Downsample-data-(if-necessary)-214\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Downsample data (if necessary)</a></div><div class=\"lev3 toc-item\"><a href=\"#Clean-data\" data-toc-modified-id=\"Clean-data-215\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Clean data</a></div><div class=\"lev3 toc-item\"><a href=\"#Save-data\" data-toc-modified-id=\"Save-data-216\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Save data</a></div><div class=\"lev1 toc-item\"><a href=\"#Headfixed-exposure\" data-toc-modified-id=\"Headfixed-exposure-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Headfixed exposure</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-behavioral-data\" data-toc-modified-id=\"Create-behavioral-data-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create behavioral data</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-neural-data\" data-toc-modified-id=\"Import-neural-data-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Import neural data</a></div><div class=\"lev3 toc-item\"><a href=\"#Save-data\" data-toc-modified-id=\"Save-data-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Save data</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:02:31.487527Z",
     "start_time": "2018-01-30T16:02:30.716941Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rung/anaconda3/envs/py2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "# %matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import custom\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='homecage'></a>\n",
    "# Homecage odor exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:11:28.083254Z",
     "start_time": "2017-12-15T13:11:28.060235Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "frame_max = 4500\n",
    "frame_dur = 200\n",
    "n_cores = 7\n",
    "ts = np.arange(0, 300000, frame_dur)\n",
    "\n",
    "# Input files\n",
    "del_tmt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/del_free-tmt.csv'\n",
    "del_pnt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/del_free-pnt.csv'\n",
    "match_file = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/matches.csv'\n",
    "\n",
    "behav_files = glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_TMT/PNOC_Behavior/*.xlsx') + \\\n",
    "              glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_PNT/PNOC_Behavior/*.xlsx')\n",
    "ca_files = glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_TMT/PNOC_Traces/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_TMT/PNOC_Spikes/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_PNT/PNOC_Traces/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_PNT/PNOC_Spikes/*.txt')\n",
    "\n",
    "# Output files\n",
    "h5_out = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/homecage.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:15:51.185607Z",
     "start_time": "2017-12-15T13:15:51.175213Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define import function\n",
    "def import_behav(filename):\n",
    "    _, subj, odor, order, epoch = os.path.splitext(os.path.basename(filename))[0].split('_')\n",
    "    data = custom.etho_extract(filename)\n",
    "    data.index = data.index * 1000\n",
    "    \n",
    "    return (subj, odor, order, epoch), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:22:16.344490Z",
     "start_time": "2017-12-15T13:21:00.376869Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a848cbd2db0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mexps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbehav_import\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_behav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbehav_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rung/anaconda3/envs/py2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    251\u001b[0m         '''\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rung/anaconda3/envs/py2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "# This will lock up often. Not sure why...\n",
    "# Lowered number of processes in pool and seems to work better... nope\n",
    "# Keep Excel files closed seems to do the trick... nah\n",
    "# Define pool AFTER defining all functions is the fix:\n",
    "#     https://stackoverflow.com/questions/2782961/yet-another-confusion-with-multiprocessing-error-module-object-has-no-attribu\n",
    "#     https://stackoverflow.com/questions/18947876/using-python-multiprocessing-pool-in-the-terminal-and-in-code-modules-for-django\n",
    "\n",
    "p = mp.Pool(processes=n_cores)\n",
    "exps, behav_import = zip(*p.map(import_behav, behav_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:22:52.112901Z",
     "start_time": "2017-12-15T13:22:45.412906Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Dropbox (Stuber Lab)/analysis/random/custom/custom.py:37: RuntimeWarning: Mean of empty slice\n",
      "  data_ds[..., bin_ds] = method(data[..., bin_pts], axis=-1)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from all animals\n",
    "# Sessions are defined as set of epochs with the same odor. For example, \n",
    "# for one animal, the three experiments the animal underwent in a single \n",
    "# day: baseline, water, odor\n",
    "\n",
    "sessions = set([x[:2] for x in exps])\n",
    "dfs = []\n",
    "\n",
    "# Combine epochs (base, h2o, odor) of the same experiment\n",
    "epoch_dict = {'1': 'base', '2': 'h2o', '3':'odor'}\n",
    "\n",
    "# Iterate over sessions\n",
    "for session in sessions:\n",
    "    subj, odor = session\n",
    "    \n",
    "    # Identify epochs of session\n",
    "    epochs = {\n",
    "        sess: behav_import[n] for n, sess in enumerate(exps)\n",
    "        if subj in sess and odor in sess\n",
    "    }\n",
    "\n",
    "    # Downsample data and create dataframe for subject (with each epoch)\n",
    "    subj_df = pd.DataFrame()\n",
    "    for epoch_key, epoch_data in epochs.iteritems():\n",
    "        old_ts = epoch_data.index\n",
    "        data = epoch_data.as_matrix()\n",
    "        data_ds = custom.resample(data, old_ts, ts, method=np.nanmean)\n",
    "        epoch_df = pd.DataFrame(data_ds, columns=epoch_data.columns, index=ts)\n",
    "        epoch_df.index = pd.MultiIndex.from_tuples(\n",
    "            [(epoch_dict[epoch_key[-1]], x) for x in epoch_df.index],\n",
    "            names=['epoch', 'timestamp']\n",
    "        )\n",
    "        subj_df = pd.concat([subj_df, epoch_df], axis=0)\n",
    "\n",
    "    subj_df.columns = pd.MultiIndex.from_tuples(\n",
    "        [epoch_key[:-1] + (x, ) for x in subj_df.columns],\n",
    "        names=['subject', 'experiment', 'order', 'feature']\n",
    "    )\n",
    "    dfs.append(subj_df)\n",
    "\n",
    "behav_df = pd.concat(dfs, axis=1, names=['subject', 'feature'])\n",
    "behav_df = behav_df.sort_index(axis=1, level=0)\n",
    "# behav_df = behav_df.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import calcium imaging data\n",
    "Each session is 1499 or 1500 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:23:58.819708Z",
     "start_time": "2017-12-15T13:23:54.817787Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "ca_import = {\n",
    "    tuple(os.path.splitext(os.path.basename(f))[0].split('_')): np.loadtxt(f, delimiter=',')\n",
    "    for f in ca_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:23:59.182841Z",
     "start_time": "2017-12-15T13:23:58.821168Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "dfs = []\n",
    "\n",
    "for exp, exp_data in ca_import.iteritems():\n",
    "    n_frames = min(exp_data.shape[1], frame_max)\n",
    "    exp_index = pd.MultiIndex.from_product([['base', 'h2o', 'odor'], ts], names=['epoch', 'time'])[:n_frames]\n",
    "    df = pd.DataFrame(exp_data.T[:n_frames], index=exp_index)\n",
    "    df.columns = pd.MultiIndex.from_tuples(\n",
    "        [exp + (x, ) for x in df.columns],\n",
    "        names=['datatype', 'subject', 'experiment', 'order', 'neuron']\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "neural_df = pd.concat(dfs, axis=1)\n",
    "neural_df = neural_df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T13:24:04.389915Z",
     "start_time": "2017-12-15T13:24:04.148083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>datatype</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Spikes</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Traces</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th colspan=\"10\" halign=\"left\">H123</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">J55</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th colspan=\"10\" halign=\"left\">TMT</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">TMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th colspan=\"10\" halign=\"left\">A</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>neuron</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">base</th>\n",
       "      <th>0</th>\n",
       "      <td>37.847</td>\n",
       "      <td>277.90</td>\n",
       "      <td>363.61</td>\n",
       "      <td>80.583</td>\n",
       "      <td>29.876</td>\n",
       "      <td>2.6306</td>\n",
       "      <td>100.18</td>\n",
       "      <td>113.040</td>\n",
       "      <td>13.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.76830</td>\n",
       "      <td>13.7460</td>\n",
       "      <td>12.1960</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>50.372</td>\n",
       "      <td>3.80910</td>\n",
       "      <td>4.16580</td>\n",
       "      <td>20.454</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65320</td>\n",
       "      <td>13.3050</td>\n",
       "      <td>11.4650</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>54.383</td>\n",
       "      <td>3.55500</td>\n",
       "      <td>3.98010</td>\n",
       "      <td>19.142</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54290</td>\n",
       "      <td>12.8790</td>\n",
       "      <td>10.7780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>51.003</td>\n",
       "      <td>3.31800</td>\n",
       "      <td>3.80270</td>\n",
       "      <td>17.913</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.080</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.43710</td>\n",
       "      <td>12.4660</td>\n",
       "      <td>10.1320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>59.857</td>\n",
       "      <td>3.09670</td>\n",
       "      <td>3.63320</td>\n",
       "      <td>24.444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.33580</td>\n",
       "      <td>12.0660</td>\n",
       "      <td>9.5253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56.137</td>\n",
       "      <td>2.89020</td>\n",
       "      <td>3.47130</td>\n",
       "      <td>22.875</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.23860</td>\n",
       "      <td>11.6790</td>\n",
       "      <td>8.9546</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>52.648</td>\n",
       "      <td>2.69740</td>\n",
       "      <td>3.31650</td>\n",
       "      <td>21.407</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.14550</td>\n",
       "      <td>11.3050</td>\n",
       "      <td>8.4181</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>49.376</td>\n",
       "      <td>2.51750</td>\n",
       "      <td>3.16870</td>\n",
       "      <td>20.034</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.05630</td>\n",
       "      <td>10.9430</td>\n",
       "      <td>7.9137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>54.250</td>\n",
       "      <td>2.34960</td>\n",
       "      <td>3.02750</td>\n",
       "      <td>33.349</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.97080</td>\n",
       "      <td>10.5920</td>\n",
       "      <td>7.4396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>50.878</td>\n",
       "      <td>2.19290</td>\n",
       "      <td>2.89250</td>\n",
       "      <td>31.209</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88880</td>\n",
       "      <td>10.2520</td>\n",
       "      <td>24.2220</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>47.716</td>\n",
       "      <td>2.04670</td>\n",
       "      <td>2.76360</td>\n",
       "      <td>29.206</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81030</td>\n",
       "      <td>9.9235</td>\n",
       "      <td>30.1270</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.750</td>\n",
       "      <td>1.91020</td>\n",
       "      <td>2.64040</td>\n",
       "      <td>27.332</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73500</td>\n",
       "      <td>9.6054</td>\n",
       "      <td>28.3220</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>52.039</td>\n",
       "      <td>1.78280</td>\n",
       "      <td>2.52270</td>\n",
       "      <td>42.496</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>90.295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.66280</td>\n",
       "      <td>9.2975</td>\n",
       "      <td>26.6250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>48.805</td>\n",
       "      <td>1.66390</td>\n",
       "      <td>2.41030</td>\n",
       "      <td>39.769</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.59370</td>\n",
       "      <td>8.9994</td>\n",
       "      <td>25.0300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>64.744</td>\n",
       "      <td>1.55290</td>\n",
       "      <td>2.30290</td>\n",
       "      <td>37.217</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52740</td>\n",
       "      <td>8.7109</td>\n",
       "      <td>23.5300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>60.720</td>\n",
       "      <td>1.44940</td>\n",
       "      <td>2.20020</td>\n",
       "      <td>34.829</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.46390</td>\n",
       "      <td>8.4316</td>\n",
       "      <td>22.1200</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56.947</td>\n",
       "      <td>1.35270</td>\n",
       "      <td>2.10210</td>\n",
       "      <td>32.594</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.40300</td>\n",
       "      <td>8.1613</td>\n",
       "      <td>20.7950</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>53.407</td>\n",
       "      <td>1.26250</td>\n",
       "      <td>2.00840</td>\n",
       "      <td>30.502</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34460</td>\n",
       "      <td>7.8997</td>\n",
       "      <td>19.5490</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>50.088</td>\n",
       "      <td>1.17830</td>\n",
       "      <td>1.91890</td>\n",
       "      <td>28.545</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.28870</td>\n",
       "      <td>7.6464</td>\n",
       "      <td>18.3780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>46.975</td>\n",
       "      <td>1.09970</td>\n",
       "      <td>1.83340</td>\n",
       "      <td>33.727</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23510</td>\n",
       "      <td>7.4013</td>\n",
       "      <td>42.0460</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.056</td>\n",
       "      <td>1.02640</td>\n",
       "      <td>1.75170</td>\n",
       "      <td>31.563</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18380</td>\n",
       "      <td>7.1640</td>\n",
       "      <td>39.5260</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>51.779</td>\n",
       "      <td>0.95794</td>\n",
       "      <td>1.67360</td>\n",
       "      <td>38.367</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13450</td>\n",
       "      <td>6.9344</td>\n",
       "      <td>37.1580</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>48.561</td>\n",
       "      <td>0.89405</td>\n",
       "      <td>1.59900</td>\n",
       "      <td>47.515</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08730</td>\n",
       "      <td>6.7121</td>\n",
       "      <td>44.1510</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45.543</td>\n",
       "      <td>0.83443</td>\n",
       "      <td>1.52770</td>\n",
       "      <td>44.466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.04210</td>\n",
       "      <td>6.4969</td>\n",
       "      <td>49.1800</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>42.712</td>\n",
       "      <td>0.77878</td>\n",
       "      <td>1.45960</td>\n",
       "      <td>41.612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99879</td>\n",
       "      <td>6.2886</td>\n",
       "      <td>46.2330</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>40.058</td>\n",
       "      <td>0.72684</td>\n",
       "      <td>1.39460</td>\n",
       "      <td>38.942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>76.817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95725</td>\n",
       "      <td>6.0870</td>\n",
       "      <td>43.4630</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>37.568</td>\n",
       "      <td>0.67837</td>\n",
       "      <td>1.33240</td>\n",
       "      <td>36.443</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91744</td>\n",
       "      <td>5.8918</td>\n",
       "      <td>40.8590</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.233</td>\n",
       "      <td>0.63313</td>\n",
       "      <td>1.27300</td>\n",
       "      <td>34.105</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87929</td>\n",
       "      <td>14.8220</td>\n",
       "      <td>38.4110</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>33.044</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>1.21630</td>\n",
       "      <td>31.916</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84272</td>\n",
       "      <td>14.3470</td>\n",
       "      <td>36.1090</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.990</td>\n",
       "      <td>0.55150</td>\n",
       "      <td>1.16210</td>\n",
       "      <td>29.868</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80767</td>\n",
       "      <td>13.8870</td>\n",
       "      <td>33.9460</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>29.064</td>\n",
       "      <td>0.51472</td>\n",
       "      <td>1.11030</td>\n",
       "      <td>27.951</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">odor</th>\n",
       "      <th>294000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.82600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.94840</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.07370</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.68530</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.63870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.90990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.55540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.34280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.75480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>104.63</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.43550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.06000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.60800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>313.55</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>214.560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.32490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.78990</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.46900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>56.513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.22280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.53190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.33740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.12850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.28530</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.21280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>69.883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.04150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.04970</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.09490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>205.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.96126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.82460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.98320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>345.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.88717</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.64900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.87750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.81879</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.62750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.77750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.75568</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.51040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.68270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.69744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.39850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.59300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.64369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.29160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.50810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>598.48</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.59407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.54829</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.09190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.35170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.50603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.99860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.27960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.46703</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.90960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.21140</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>121.740</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.43103</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.82440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.14690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.39781</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.74310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.08570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.36715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.80246</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.33885</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.76669</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.97310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298400</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.31273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.73252</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.92123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298600</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.28863</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69987</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.87214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298800</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.26638</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.66867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.82565</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299000</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.24585</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.63887</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.78165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299200</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.647</td>\n",
       "      <td>75.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.22690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.61039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.73999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.20942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.58319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.70055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.88300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.96700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.12500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 1062 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "datatype      Spikes                                                    \\\n",
       "subject         H123                                                     \n",
       "experiment       TMT                                                     \n",
       "order              A                                                     \n",
       "neuron            0       1       2        3        4       5       6    \n",
       "epoch time                                                               \n",
       "base  0       37.847  277.90  363.61   80.583   29.876  2.6306  100.18   \n",
       "      200      0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      400      0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      600      0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      800      0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      1000     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      1200     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      1400     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      1600     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      1800     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      2000     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      2200     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      2400     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      2600     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      2800     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      3000     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      3200     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      3400     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      3600     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      3800     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      4000     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      4200     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      4400     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      4600     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      4800     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      5000     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      5200     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      5400     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      5600     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      5800     0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "...              ...     ...     ...      ...      ...     ...     ...   \n",
       "odor  294000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      294200   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      294400   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      294600   0.000    0.00    0.00    0.000    0.000  0.0000  104.63   \n",
       "      294800   0.000    0.00    0.00    0.000    0.000  0.0000  313.55   \n",
       "      295000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      295200   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      295400   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      295600   0.000  205.72    0.00    0.000    0.000  0.0000    0.00   \n",
       "      295800   0.000  345.93    0.00    0.000    0.000  0.0000    0.00   \n",
       "      296000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      296200   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      296400   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      296600   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      296800   0.000    0.00  598.48    0.000    0.000  0.0000    0.00   \n",
       "      297000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      297200   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      297400   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      297600   0.000    0.00    0.00    0.000  121.740  0.0000    0.00   \n",
       "      297800   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      298000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      298200   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      298400   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      298600   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      298800   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      299000   0.000    0.00    0.00    0.000    0.000  0.0000    0.00   \n",
       "      299200   0.000    0.00    0.00  198.950    0.000  0.0000    0.00   \n",
       "      299400     NaN     NaN     NaN      NaN      NaN     NaN     NaN   \n",
       "      299600     NaN     NaN     NaN      NaN      NaN     NaN     NaN   \n",
       "      299800     NaN     NaN     NaN      NaN      NaN     NaN     NaN   \n",
       "\n",
       "datatype                               ...    Traces                    \\\n",
       "subject                                ...       J55                     \n",
       "experiment                             ...       TMT                     \n",
       "order                                  ...         B                     \n",
       "neuron             7       8        9  ...        56       57       58   \n",
       "epoch time                             ...                               \n",
       "base  0       113.040  13.144    0.000 ...   2.76830  13.7460  12.1960   \n",
       "      200       0.000   0.000    0.000 ...   2.65320  13.3050  11.4650   \n",
       "      400       0.000   0.000    0.000 ...   2.54290  12.8790  10.7780   \n",
       "      600     100.080   0.000    0.000 ...   2.43710  12.4660  10.1320   \n",
       "      800       0.000   0.000    0.000 ...   2.33580  12.0660   9.5253   \n",
       "      1000      0.000   0.000    0.000 ...   2.23860  11.6790   8.9546   \n",
       "      1200      0.000   0.000    0.000 ...   2.14550  11.3050   8.4181   \n",
       "      1400      0.000   0.000    0.000 ...   2.05630  10.9430   7.9137   \n",
       "      1600      0.000   0.000    0.000 ...   1.97080  10.5920   7.4396   \n",
       "      1800      0.000   0.000    0.000 ...   1.88880  10.2520  24.2220   \n",
       "      2000      0.000   0.000    0.000 ...   1.81030   9.9235  30.1270   \n",
       "      2200      0.000   0.000    0.000 ...   1.73500   9.6054  28.3220   \n",
       "      2400      0.000   0.000   90.295 ...   1.66280   9.2975  26.6250   \n",
       "      2600      0.000   0.000    0.000 ...   1.59370   8.9994  25.0300   \n",
       "      2800      0.000   0.000    0.000 ...   1.52740   8.7109  23.5300   \n",
       "      3000      0.000   0.000    0.000 ...   1.46390   8.4316  22.1200   \n",
       "      3200      0.000   0.000    0.000 ...   1.40300   8.1613  20.7950   \n",
       "      3400      0.000   0.000    0.000 ...   1.34460   7.8997  19.5490   \n",
       "      3600      0.000   0.000    0.000 ...   1.28870   7.6464  18.3780   \n",
       "      3800      0.000   0.000    0.000 ...   1.23510   7.4013  42.0460   \n",
       "      4000      0.000   0.000    0.000 ...   1.18380   7.1640  39.5260   \n",
       "      4200      0.000   0.000    0.000 ...   1.13450   6.9344  37.1580   \n",
       "      4400      0.000   0.000    0.000 ...   1.08730   6.7121  44.1510   \n",
       "      4600      0.000   0.000    0.000 ...   1.04210   6.4969  49.1800   \n",
       "      4800      0.000   0.000    0.000 ...   0.99879   6.2886  46.2330   \n",
       "      5000      0.000   0.000   76.817 ...   0.95725   6.0870  43.4630   \n",
       "      5200      0.000   0.000    0.000 ...   0.91744   5.8918  40.8590   \n",
       "      5400      0.000   0.000    0.000 ...   0.87929  14.8220  38.4110   \n",
       "      5600      0.000   0.000    0.000 ...   0.84272  14.3470  36.1090   \n",
       "      5800      0.000   0.000    0.000 ...   0.80767  13.8870  33.9460   \n",
       "...               ...     ...      ... ...       ...      ...      ...   \n",
       "odor  294000    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      294200    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      294400    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      294600    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      294800    0.000   0.000  214.560 ...   0.00000   0.0000   0.0000   \n",
       "      295000    0.000   0.000   56.513 ...   0.00000   0.0000   0.0000   \n",
       "      295200    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      295400    0.000   0.000   69.883 ...   0.00000   0.0000   0.0000   \n",
       "      295600    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      295800    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      296000    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      296200    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      296400    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      296600    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      296800    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      297000    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      297200    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      297400    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      297600    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      297800    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      298000    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      298200    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      298400    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      298600    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      298800    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      299000    0.000   0.000    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      299200   72.647  75.750    0.000 ...   0.00000   0.0000   0.0000   \n",
       "      299400      NaN     NaN      NaN ...   0.00000   0.0000   0.0000   \n",
       "      299600      NaN     NaN      NaN ...   0.00000   0.0000   0.0000   \n",
       "      299800      NaN     NaN      NaN ...   0.00000   0.0000   0.0000   \n",
       "\n",
       "datatype                                                                 \n",
       "subject                                                                  \n",
       "experiment                                                               \n",
       "order                                                                    \n",
       "neuron              59      60       61       62      63        64   65  \n",
       "epoch time                                                               \n",
       "base  0        0.00000  50.372  3.80910  4.16580  20.454   0.00000  0.0  \n",
       "      200      0.00000  54.383  3.55500  3.98010  19.142   0.00000  0.0  \n",
       "      400      0.00000  51.003  3.31800  3.80270  17.913   0.00000  0.0  \n",
       "      600      0.00000  59.857  3.09670  3.63320  24.444   0.00000  0.0  \n",
       "      800      0.00000  56.137  2.89020  3.47130  22.875   0.00000  0.0  \n",
       "      1000     0.00000  52.648  2.69740  3.31650  21.407   0.00000  0.0  \n",
       "      1200     0.00000  49.376  2.51750  3.16870  20.034   0.00000  0.0  \n",
       "      1400     0.00000  54.250  2.34960  3.02750  33.349   0.00000  0.0  \n",
       "      1600     0.00000  50.878  2.19290  2.89250  31.209   0.00000  0.0  \n",
       "      1800     0.00000  47.716  2.04670  2.76360  29.206   0.00000  0.0  \n",
       "      2000     0.00000  44.750  1.91020  2.64040  27.332   0.00000  0.0  \n",
       "      2200     0.00000  52.039  1.78280  2.52270  42.496   0.00000  0.0  \n",
       "      2400     0.00000  48.805  1.66390  2.41030  39.769   0.00000  0.0  \n",
       "      2600     0.00000  64.744  1.55290  2.30290  37.217   0.00000  0.0  \n",
       "      2800     0.00000  60.720  1.44940  2.20020  34.829   0.00000  0.0  \n",
       "      3000     0.00000  56.947  1.35270  2.10210  32.594   0.00000  0.0  \n",
       "      3200     0.00000  53.407  1.26250  2.00840  30.502   0.00000  0.0  \n",
       "      3400     0.00000  50.088  1.17830  1.91890  28.545   0.00000  0.0  \n",
       "      3600     0.00000  46.975  1.09970  1.83340  33.727   0.00000  0.0  \n",
       "      3800     0.00000  44.056  1.02640  1.75170  31.563   0.00000  0.0  \n",
       "      4000     0.00000  51.779  0.95794  1.67360  38.367   0.00000  0.0  \n",
       "      4200     0.00000  48.561  0.89405  1.59900  47.515   0.00000  0.0  \n",
       "      4400     0.00000  45.543  0.83443  1.52770  44.466   0.00000  0.0  \n",
       "      4600     0.00000  42.712  0.77878  1.45960  41.612   0.00000  0.0  \n",
       "      4800     0.00000  40.058  0.72684  1.39460  38.942   0.00000  0.0  \n",
       "      5000     0.00000  37.568  0.67837  1.33240  36.443   0.00000  0.0  \n",
       "      5200     0.00000  35.233  0.63313  1.27300  34.105   0.00000  0.0  \n",
       "      5400     0.00000  33.044  0.59091  1.21630  31.916   0.00000  0.0  \n",
       "      5600     0.00000  30.990  0.55150  1.16210  29.868   0.00000  0.0  \n",
       "      5800     0.00000  29.064  0.51472  1.11030  27.951   0.00000  0.0  \n",
       "...                ...     ...      ...      ...     ...       ...  ...  \n",
       "odor  294000   1.82600   0.000  0.00000  6.94840   0.000   3.07370  0.0  \n",
       "      294200   1.68530   0.000  0.00000  6.63870   0.000   2.90990  0.0  \n",
       "      294400   1.55540   0.000  0.00000  6.34280   0.000   2.75480  0.0  \n",
       "      294600   1.43550   0.000  0.00000  6.06000   0.000   2.60800  0.0  \n",
       "      294800   1.32490   0.000  0.00000  5.78990   0.000   2.46900  0.0  \n",
       "      295000   1.22280   0.000  0.00000  5.53190   0.000   2.33740  0.0  \n",
       "      295200   1.12850   0.000  0.00000  5.28530   0.000   2.21280  0.0  \n",
       "      295400   1.04150   0.000  0.00000  5.04970   0.000   2.09490  0.0  \n",
       "      295600   0.96126   0.000  0.00000  4.82460   0.000   1.98320  0.0  \n",
       "      295800   0.88717   0.000  0.00000  3.64900   0.000   1.87750  0.0  \n",
       "      296000   0.81879   0.000  0.00000  2.62750   0.000   1.77750  0.0  \n",
       "      296200   0.75568   0.000  0.00000  2.51040   0.000   1.68270  0.0  \n",
       "      296400   0.69744   0.000  0.00000  2.39850   0.000   1.59300  0.0  \n",
       "      296600   0.64369   0.000  0.00000  2.29160   0.000   1.50810  0.0  \n",
       "      296800   0.59407   0.000  0.00000  2.18950   0.000   1.42780  0.0  \n",
       "      297000   0.54829   0.000  0.00000  2.09190   0.000   1.35170  0.0  \n",
       "      297200   0.50603   0.000  0.00000  1.99860   0.000   1.27960  0.0  \n",
       "      297400   0.46703   0.000  0.00000  1.90960   0.000   1.21140  0.0  \n",
       "      297600   0.43103   0.000  0.00000  1.82440   0.000   1.14690  0.0  \n",
       "      297800   0.39781   0.000  0.00000  1.74310   0.000   1.08570  0.0  \n",
       "      298000   0.36715   0.000  0.00000  0.80246   0.000   1.02790  0.0  \n",
       "      298200   0.33885   0.000  0.00000  0.76669   0.000   0.97310  0.0  \n",
       "      298400   0.31273   0.000  0.00000  0.73252   0.000   0.92123  0.0  \n",
       "      298600   0.28863   0.000  0.00000  0.69987   0.000   0.87214  0.0  \n",
       "      298800   0.26638   0.000  0.00000  0.66867   0.000   0.82565  0.0  \n",
       "      299000   0.24585   0.000  0.00000  0.63887   0.000   0.78165  0.0  \n",
       "      299200   0.22690   0.000  0.00000  0.61039   0.000   0.73999  0.0  \n",
       "      299400   0.20942   0.000  0.00000  0.58319   0.000   0.70055  0.0  \n",
       "      299600  11.88300   0.000  0.00000  0.00000   0.000   0.00000  0.0  \n",
       "      299800  10.96700   0.000  0.00000  0.00000   0.000  12.12500  0.0  \n",
       "\n",
       "[4500 rows x 1062 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T09:15:08.265800Z",
     "start_time": "2017-11-08T09:15:07.560809Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Spikes', 'H185', 'TMT', 'A') 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAEyCAYAAABUJ1mnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5P8H7XN9nCR0r8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdddc0f3450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check\n",
    "n = np.random.randint(len(ca_import))\n",
    "ca_iter = ca_import.iteritems()\n",
    "for _ in xrange(n):\n",
    "    key, val = ca_iter.next()\n",
    "\n",
    "c = np.random.randint(len(val))\n",
    "print key, c\n",
    "\n",
    "x1 = val[c]\n",
    "x2 = neural_df[key + (c, )].as_matrix()\n",
    "f = min(len(x1), len(x2))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(15, 5))\n",
    "ax[0].plot(x1);\n",
    "ax[1].plot(x2);\n",
    "ax[2].plot(x1);\n",
    "ax[2].plot(x1);\n",
    "ax[3].plot(x1[:f] - x2[:f]);\n",
    "np.array_equal(x1[:f], x2[:f])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T09:16:52.763234Z",
     "start_time": "2017-11-08T09:16:52.717540Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "\n",
    "# Import files with cells to delete\n",
    "delete_import = pd.concat(\n",
    "    [pd.read_csv(del_pnt, delimiter=','), pd.read_csv(del_tmt, delimiter=',')],\n",
    "    axis=1, keys=['PNT', 'TMT']\n",
    ")\n",
    "delete_import.columns = pd.MultiIndex.from_tuples(\n",
    "    [[x[0], ] + x[1].split('_') for x in delete_import.columns],\n",
    "    names=['experiment', 'subject']\n",
    ")\n",
    "delete_import = delete_import.unstack().dropna()\n",
    "delete_import = delete_import.reset_index(level=-1, drop=True)\n",
    "delete_import = delete_import.reorder_levels(['subject', 'experiment'])\n",
    "delete_import -= 1\n",
    "\n",
    "cells_to_delete = pd.concat(\n",
    "    [delete_import.astype(int)] * 2,\n",
    "    axis=1, keys=['index', 'to_delete']\n",
    ").set_index('index', append=True).index.tolist()\n",
    "to_delete = [(exp, ) + x for x in cells_to_delete for exp in set(['Spikes', 'Traces'])]\n",
    "\n",
    "before = neural_df.shape[1]\n",
    "neural_df = neural_df.reorder_levels(['datatype', 'subject', 'experiment', 'neuron', 'order'], axis=1)\n",
    "neural_df = neural_df.drop(to_delete, axis=1, errors='ignore')\n",
    "neural_df = neural_df.dropna(axis=0)\n",
    "neural_df = neural_df.reorder_levels(['datatype', 'subject', 'experiment', 'order', 'neuron'], axis=1)\n",
    "after = neural_df.shape[1]\n",
    "print('{} neurons deleted. {} supposed to be deleted'.format(before - after, len(to_delete)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T09:50:39.059485Z",
     "start_time": "2017-11-08T09:50:38.780311Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches for H123\n",
      "No peanut oil experiments for H123\n",
      "No matches for H169\n",
      "No peanut oil experiments for H169\n",
      "No matches for H170\n",
      "No peanut oil experiments for H170\n",
      "No matches for H185\n",
      "No peanut oil experiments for H185\n",
      "No matches for H186\n",
      "No peanut oil experiments for H186\n",
      "No matches for H187\n",
      "No peanut oil experiments for H187\n",
      "H188 90\n",
      "J1 36\n",
      "No matches for J52\n",
      "No peanut oil experiments for J52\n",
      "No matches for J53\n",
      "No TMT experiments found for J53\n",
      "No matches for J54\n",
      "No TMT experiments found for J54\n",
      "No matches for J55\n",
      "No peanut oil experiments for J55\n"
     ]
    }
   ],
   "source": [
    "# Match cells\n",
    "# Iterate over experiments, choosing only cells in peanut oil ones. Assign number based on match file.\n",
    "\n",
    "match_import = pd.read_csv(match_file, delimiter=',', header=0)\n",
    "match_import -= 1  # start indexing at 0\n",
    "\n",
    "neural_df_new = []  # new dataframe with updated matched cell labelling\n",
    "# for grp, grp_df in neural_df.loc[slice(None), (slice(None), 'H188')].groupby(level='subject', axis=1):\n",
    "for grp, grp_df in neural_df.groupby(level='subject', axis=1):\n",
    "    # Check if cell is in matches file\n",
    "    if grp in match_import:\n",
    "        key = match_import[grp]\n",
    "    else:\n",
    "        print('No matches for {}'.format(grp))\n",
    "        \n",
    "        # Check if there are peanut oil experiments\n",
    "        pnt_cells = [x[-1] for x in grp_df.xs('PNT', axis=1, level='experiment')]\n",
    "        if pnt_cells:\n",
    "            # Make a map that matches all cells to nan\n",
    "            key = np.nan * np.zeros(max([x[-1] for x in grp_df.xs('PNT', axis=1, level='experiment')]) + 1)\n",
    "        else:\n",
    "            print('No peanut oil experiments for {}'.format(grp))\n",
    "            neural_df_new.append(grp_df)\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "#         n_tmt_cells = max([x[-1] for x in grp_df.xs('TMT', axis=1, level='experiment')]) + 1\n",
    "        n_tmt_cells = int(key.max()) + 1  # Sometimes matches go higher than actual TMT cells on hand\n",
    "        print grp, n_tmt_cells\n",
    "    except ValueError:\n",
    "        print('No TMT experiments found for {}'.format(grp))\n",
    "        n_tmt_cells = 0\n",
    "\n",
    "    grp_df = grp_df.stack(level='datatype')\n",
    "    new_cols = grp_df.columns.tolist()\n",
    "    for n, col in enumerate(new_cols):  # should groupby neuron here (to include spikes, traces)\n",
    "        # Only look at the peanut oil cells (since that's the reference in match.csv)\n",
    "        if 'PNT' in col:\n",
    "            neuron_id = col[-1]\n",
    "            matched_cell = key[neuron_id]\n",
    "#             pdb.set_trace()\n",
    "            if np.isfinite(matched_cell) and matched_cell < n_tmt_cells:\n",
    "                new_cols[n] = col[:-1] + (int(matched_cell), )  # should rename all instances of neuron\n",
    "            else:\n",
    "                new_cols[n] = col[:-1] + (col[-1] + n_tmt_cells, )\n",
    "\n",
    "    grp_df.columns = pd.MultiIndex.from_tuples(new_cols, names=grp_df.columns.names)\n",
    "    grp_df = grp_df.unstack(level='datatype').reorder_levels(['datatype', 'subject', 'experiment', 'order', 'neuron'], axis=1)\n",
    "    neural_df_new.append(grp_df)\n",
    "\n",
    "neural_df_matched = pd.concat(neural_df_new, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T09:50:44.579461Z",
     "start_time": "2017-11-08T09:50:42.981926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fddc32d5410>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEKCAYAAADgochqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS5IkSTUWyZIkSVKNRbIkSZJU8/8As+ketyh2ZwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fddc331a350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check registration\n",
    "animal = 'H188'\n",
    "cell_before = 44\n",
    "cell_after = 46\n",
    "\n",
    "\n",
    "x1 = neural_df.loc[slice(None), ('Spikes', animal, 'PNT', 'A', cell_before)]\n",
    "x2 = neural_df_matched.loc[slice(None), ('Spikes', animal, 'PNT', 'A', cell_after)]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "x1.plot(ax=axes[0])\n",
    "x2.plot(ax=axes[1])\n",
    "axes[2].plot(x1.as_matrix().flatten() - x2.as_matrix().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T09:50:47.756129Z",
     "start_time": "2017-11-08T09:50:47.588069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(h5_out) as hf:\n",
    "    hf['behav'] = behav_df\n",
    "    hf['neural'] = neural_df_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='epm'></a>\n",
    "# Elevated-plus maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T18:01:55.719816Z",
     "start_time": "2018-01-30T18:01:55.707833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behav_source = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_EPM/PNOC_Behavior/*.xlsx'\n",
    "trace_source = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_EPM/PNOC_Traces/*.txt'\n",
    "event_source = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/PNOC_EPM/PNOC_Spikes/*.txt'\n",
    "\n",
    "del_epm = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/del_epm.csv'\n",
    "\n",
    "h5_outfile = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/miniscope/epm.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:04:23.664327Z",
     "start_time": "2018-01-30T16:04:23.657406Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "bin_size = 200\n",
    "exp_dur = 600000\n",
    "n_cores = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:33:00.422959Z",
     "start_time": "2018-01-30T16:32:24.498416Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "def import_behav(filename):\n",
    "    _, subj, epoch = os.path.splitext(os.path.basename(filename))[0].split('_')\n",
    "    data = custom.etho_extract(filename)\n",
    "    data.index = data.index * 1000\n",
    "    \n",
    "    return (subj, epoch), data\n",
    "\n",
    "behav_files = glob.glob(behav_source)\n",
    "p = mp.Pool(processes=n_cores)\n",
    "exps, behav_import = zip(*p.map(import_behav, behav_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:33:04.214114Z",
     "start_time": "2018-01-30T16:33:04.204344Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct for extra 10 s at beginning of behavioral data\n",
    "for data in behav_import:\n",
    "    data.index -= 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:19.971600Z",
     "start_time": "2018-01-30T16:39:16.866493Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Dropbox (Stuber Lab)/analysis/random/custom/custom.py:37: RuntimeWarning: Mean of empty slice\n",
      "  data_ds[..., bin_ds] = method(data[..., bin_pts], axis=-1)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from all animals\n",
    "\n",
    "ts = np.arange(0, exp_dur, bin_size)\n",
    "subjs = [x for x, _ in exps]\n",
    "\n",
    "dfs = {}  # Dictionary to store DataFrame from each animal\n",
    "for subj, data in zip(subjs, behav_import):\n",
    "    data_ds = custom.resample(data, data.index, ts, method=np.nanmean)\n",
    "    ds_df = pd.DataFrame(data_ds, columns=data.columns, index=ts)\n",
    "    ds_df.columns.names = ['feature']\n",
    "    ds_df.index.names = ['timestamp']\n",
    "    dfs[subj] = ds_df\n",
    "\n",
    "# Create DataFrame for all data\n",
    "behav_df = pd.concat(dfs, axis=1, names=['subject', 'feature'])\n",
    "behav_df = behav_df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import calcium imaging data\n",
    "Each session is 1499 or 1500 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:26.191746Z",
     "start_time": "2018-01-30T16:39:26.186765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "frame_dur = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:32.779315Z",
     "start_time": "2018-01-30T16:39:31.432162Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gather files\n",
    "trace_files = glob.glob(trace_source)\n",
    "event_files = glob.glob(event_source)\n",
    "\n",
    "# Import data\n",
    "trace_import = {\n",
    "    os.path.basename(f).split('_')[1]: pd.DataFrame(np.loadtxt(f, delimiter=',').T)\n",
    "    for f in trace_files\n",
    "}\n",
    "event_import = {\n",
    "    os.path.basename(f).split('_')[1]: pd.DataFrame(np.loadtxt(f, delimiter=',').T)\n",
    "    for f in event_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:39:49.035813Z",
     "start_time": "2018-01-30T16:39:48.922971Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "\n",
    "trace_df = pd.concat(trace_import, axis=1)\n",
    "event_df = pd.concat(event_import, axis=1)\n",
    "neural_df = pd.concat([trace_df, event_df], axis=1, keys=['trace', 'event'], names=['datatype', 'subject', 'neuron'])\n",
    "neural_df.index = np.arange(0, exp_dur, frame_dur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:17:21.273714Z",
     "start_time": "2017-11-03T23:17:22.069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = np.arange(0, exp_dur, bin_size)\n",
    "data_ds = custom.resample(neural_df_orig, neural_df.index, ts, method=np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T16:40:52.905082Z",
     "start_time": "2018-01-30T16:40:52.832597Z"
    }
   },
   "outputs": [],
   "source": [
    "neural_df = pd.DataFrame(neural_df, columns=neural_df.columns, index=ts)\n",
    "neural_df.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T17:57:56.341579Z",
     "start_time": "2018-01-30T17:57:56.276357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "\n",
    "# Import files with cells to delete\n",
    "delete_import = pd.read_csv(del_epm, delimiter=',')\n",
    "delete_import -= 1\n",
    "delete_import = delete_import.unstack().dropna()\n",
    "delete_import = delete_import.reset_index(level=-1, drop=True).astype(int)\n",
    "delete_import = delete_import.reset_index()\n",
    "delete_import.columns = ['subject', 'neuron']\n",
    "\n",
    "# Delete cells\n",
    "neural_df_cleaned = neural_df.drop([('trace', ) + tuple(x) for x in delete_import.as_matrix()] + [('event', ) + tuple(x) for x in delete_import.as_matrix()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T17:57:59.080731Z",
     "start_time": "2018-01-30T17:57:58.905753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rung/anaconda2/lib/python2.7/site-packages/pandas/io/pytables.py:486: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->unicode,key->axis0_level1] [items->None]\n",
      "\n",
      "  self.put(key, value)\n",
      "/home/rung/anaconda2/lib/python2.7/site-packages/pandas/io/pytables.py:486: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->unicode,key->block0_items_level1] [items->None]\n",
      "\n",
      "  self.put(key, value)\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(h5_outfile) as hf:\n",
    "    hf['behav'] = behav_df\n",
    "    hf['neural'] = neural_df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='headfixed'></a>\n",
    "# Headfixed exposure\n",
    "Create behavioral file with `pupilize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:06:13.066793Z",
     "start_time": "2017-11-05T17:06:13.047357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_dur = 200\n",
    "threshold = 225\n",
    "\n",
    "# Input files\n",
    "del_pnt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/del_hf-pnt-old.csv'\n",
    "del_tmt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/del_hf-tmt-old.csv'\n",
    "# hf_match_file = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/matches.csv'\n",
    "\n",
    "raw_data_pnt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFPNT/PNOC_Behavior'\n",
    "raw_data_tmt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFTMT/PNOC_Behavior'\n",
    "\n",
    "# ca_files = glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFPNT/PNOC_Traces/*.txt') + \\\n",
    "#            glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFTMT/PNOC_Traces/*.txt') + \\\n",
    "#            glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFPNT/PNOC_Spikes/*.txt') + \\\n",
    "#            glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFTMT/PNOC_Spikes/*.txt')\n",
    "\n",
    "ca_files = glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFPNT/PNOC_Traces/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFTMT/PNOC_Traces/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFPNT/PNOC_Spikes/*.txt') + \\\n",
    "           glob.glob('/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/2P Data/PNOC_HFTMT/PNOC_Spikes/*.txt')\n",
    "\n",
    "# Output files\n",
    "h5_out = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/headfixed_180328.h5'\n",
    "h5_out_pnt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/hf-data-pnt.h5'\n",
    "h5_out_tmt = '/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/hf-data-tmt.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:25:16.922165Z",
     "start_time": "2017-11-04T19:03:00.067040Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: activate-gfortran_linux-64.sh made the following environmental changes:\n",
      "+DEBUG_FFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fcheck=all -fbacktrace -fimplicit-none -fvar-tracking-assignments -pipe\n",
      "+DEBUG_FORTRANFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fcheck=all -fbacktrace -fimplicit-none -fvar-tracking-assignments -pipe\n",
      "+F77=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+F95=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-f95\n",
      "+FC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+FFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+FORTRANFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+GFORTRAN=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+HOST=x86_64-conda_cos6-linux-gnu\n",
      "INFO: activate-binutils_linux-64.sh made the following environmental changes:\n",
      "+ADDR2LINE=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-addr2line\n",
      "+AR=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ar\n",
      "+AS=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-as\n",
      "+CXXFILT=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-c++filt\n",
      "+ELFEDIT=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-elfedit\n",
      "+GPROF=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gprof\n",
      "+LD_GOLD=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ld.gold\n",
      "+LD=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ld\n",
      "+NM=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-nm\n",
      "+OBJCOPY=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-objcopy\n",
      "+OBJDUMP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-objdump\n",
      "+RANLIB=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ranlib\n",
      "+READELF=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-readelf\n",
      "+SIZE=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-size\n",
      "+STRINGS=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-strings\n",
      "+STRIP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-strip\n",
      "INFO: activate-gxx_linux-64.sh made the following environmental changes:\n",
      "+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+CXX=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-c++\n",
      "+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe\n",
      "+GXX=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-g++\n",
      "INFO: activate-gcc_linux-64.sh made the following environmental changes:\n",
      "+CC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-cc\n",
      "+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2\n",
      "+CPP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-cpp\n",
      "+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe\n",
      "+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og\n",
      "+GCC_AR=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar\n",
      "+GCC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc\n",
      "+GCC_NM=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm\n",
      "+GCC_RANLIB=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib\n",
      "+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now\n",
      "+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu\n",
      "Analyzing Behavior_J53_PNT_A_P1_3.h5...\n",
      "Analyzing Behavior_J53_PNT_A_P2_3.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P2_2.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P1_1.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P2_3.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P1_3.h5...\n",
      "Analyzing Behavior_J55_PNT_A_P1_1.h5...\n",
      "Analyzing Behavior_J50_PNT_B_P1_3.h5...\n",
      "Analyzing Behavior_J31_PNT_B_P1_2.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P2_3.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P2_1.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P2_2.h5...\n",
      "Analyzing Behavior_J31_PNT_B_P1_1.h5...\n",
      "Analyzing Behavior_J55_PNT_A_P1_2.h5...\n",
      "Analyzing Behavior_J50_PNT_B_P1_1.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P1_1.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P1_3.h5...\n",
      "Analyzing Behavior_J31_PNT_B_P1_3.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P2_1.h5...\n",
      "Analyzing Behavior_J53_PNT_A_P2_1.h5...\n",
      "Analyzing Behavior_J53_PNT_A_P2_2.h5...\n",
      "Analyzing Behavior_J50_PNT_B_P1_2.h5...\n",
      "Analyzing Behavior_J53_PNT_A_P1_1.h5...\n",
      "Analyzing Behavior_J54_PNT_A_P1_2.h5...\n",
      "Analyzing Behavior_J51_PNT_B_P1_2.h5...\n",
      "Analyzing Behavior_J55_PNT_A_P1_3.h5...\n",
      "Analyzing Behavior_J53_PNT_A_P1_2.h5...\n",
      "All done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rung/anaconda3/envs/py2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:67: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('pupil', ), pupil_resampled)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:68: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('trials', ), trials)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:69: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('rail_home', ), rail_home)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:70: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('rail_leave', ), rail_leave)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:71: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('track', ), track)\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$h5_out_pnt\" \"$raw_data_pnt\" \"$frame_dur\" \"$threshold\"\n",
    "\n",
    "source activate py2\n",
    "\"/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py\" -n 7 -t $4 -b $3 -o \"$1\" \"$2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:39:22.711014Z",
     "start_time": "2017-11-04T19:25:16.959008Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: activate-gfortran_linux-64.sh made the following environmental changes:\n",
      "+DEBUG_FFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fcheck=all -fbacktrace -fimplicit-none -fvar-tracking-assignments -pipe\n",
      "+DEBUG_FORTRANFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fcheck=all -fbacktrace -fimplicit-none -fvar-tracking-assignments -pipe\n",
      "+F77=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+F95=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-f95\n",
      "+FC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+FFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+FORTRANFLAGS=-fopenmp -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+GFORTRAN=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gfortran\n",
      "+HOST=x86_64-conda_cos6-linux-gnu\n",
      "INFO: activate-binutils_linux-64.sh made the following environmental changes:\n",
      "+ADDR2LINE=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-addr2line\n",
      "+AR=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ar\n",
      "+AS=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-as\n",
      "+CXXFILT=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-c++filt\n",
      "+ELFEDIT=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-elfedit\n",
      "+GPROF=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gprof\n",
      "+LD_GOLD=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ld.gold\n",
      "+LD=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ld\n",
      "+NM=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-nm\n",
      "+OBJCOPY=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-objcopy\n",
      "+OBJDUMP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-objdump\n",
      "+RANLIB=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-ranlib\n",
      "+READELF=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-readelf\n",
      "+SIZE=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-size\n",
      "+STRINGS=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-strings\n",
      "+STRIP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-strip\n",
      "INFO: activate-gxx_linux-64.sh made the following environmental changes:\n",
      "+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+CXX=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-c++\n",
      "+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe\n",
      "+GXX=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-g++\n",
      "INFO: activate-gcc_linux-64.sh made the following environmental changes:\n",
      "+CC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-cc\n",
      "+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe\n",
      "+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2\n",
      "+CPP=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-cpp\n",
      "+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe\n",
      "+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og\n",
      "+GCC_AR=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar\n",
      "+GCC=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc\n",
      "+GCC_NM=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm\n",
      "+GCC_RANLIB=/home/rung/anaconda3/envs/py2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib\n",
      "+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now\n",
      "+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu\n",
      "Analyzing Behavior_J52_TMT_A_P1_3.h5...\n",
      "Analyzing Behavior_J31_TMT_A_P1_2.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P2_3.h5...\n",
      "Analyzing Behavior_J52_TMT_A_P1_2.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P2_3.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P1_1.h5...\n",
      "Analyzing Behavior_J52_TMT_A_P2_1.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P2_2.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P1_3.h5...\n",
      "Analyzing Behavior_J55_TMT_B_P1_3.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P1_2.h5...\n",
      "Analyzing Behavior_J52_TMT_A_P2_2.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P1_3.h5...\n",
      "Analyzing Behavior_J31_TMT_A_P1_1.h5...\n",
      "Analyzing Behavior_J55_TMT_B_P1_1.h5...\n",
      "Analyzing Behavior_J55_TMT_B_P1_2.h5...\n",
      "Analyzing Behavior_J52_TMT_A_P2_3.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P2_2.h5...\n",
      "Analyzing Behavior_J50_TMT_A_P1_1.h5...\n",
      "Analyzing Behavior_J31_TMT_A_P1_3.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P1_2.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P1_1.h5...\n",
      "Analyzing Behavior_J50_TMT_A_P1_3.h5...\n",
      "Analyzing Behavior_J51_TMT_A_P2_1.h5...\n",
      "Analyzing Behavior_J53_TMT_B_P2_1.h5...\n",
      "Analyzing Behavior_J50_TMT_A_P1_2.h5...\n",
      "Analyzing Behavior_J52_TMT_A_P1_1.h5...\n",
      "All done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rung/anaconda3/envs/py2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:67: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('pupil', ), pupil_resampled)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:68: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('trials', ), trials)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:69: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('rail_home', ), rail_home)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:70: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('rail_leave', ), rail_leave)\n",
      "/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py:71: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(epoch_dict[epoch], col_name + ('track', ), track)\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$h5_out_tmt\" \"$raw_data_tmt\" \"$frame_dur\" \"$threshold\"\n",
    "\n",
    "source activate py2\n",
    "\"/data/Dropbox (Stuber Lab)/analysis/pnoc/organize_behav.py\" -n 7 -t $4 -b $3 -o \"$1\" \"$2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:02.257839Z",
     "start_time": "2017-11-04T19:45:01.406727Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "\n",
    "# Read individual dataset files\n",
    "with pd.HDFStore(h5_out_pnt, 'r') as hf_pnt, pd.HDFStore(h5_out_tmt, 'r') as hf_tmt:\n",
    "    df_behav = pd.concat(\n",
    "        [hf_pnt['behav'], hf_tmt['behav']],\n",
    "        axis=1,\n",
    "        keys=['PNT', 'TMT'],\n",
    "        names=['experiment', ] + hf_pnt['behav'].columns.names\n",
    "    )\n",
    "\n",
    "# Rename index\n",
    "df_behav = df_behav.rename(index={'ctrl': 'h2o', 'stim': 'odor'})\n",
    "\n",
    "# Combine datasets\n",
    "with pd.HDFStore(h5_out) as hf:\n",
    "    hf['behav'] = df_behav\n",
    "\n",
    "# Remove individual dataset files\n",
    "os.remove(h5_out_pnt)\n",
    "os.remove(h5_out_tmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/Dropbox (Stuber Lab)/We PNOC-ing/Latest PNOC Data/hf-data-tmt.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_out_tmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T16:52:23.150758Z",
     "start_time": "2017-11-05T16:52:23.144337Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "frames_per_epoch = 1505\n",
    "frame_period = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check frame counts on new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T16:52:24.417508Z",
     "start_time": "2017-11-05T16:52:24.370900Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of frames for each epoch\n",
    "frame_ct = {\n",
    "    'J31_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J50_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J51_TMT_A_P1': [1504, 1504, 1504],\n",
    "    'J51_TMT_A_P2': [1504, 1504, 1504],\n",
    "    'J52_TMT_A_P1': [1505, 1505, 1505],\n",
    "    'J52_TMT_A_P2': [1505, 1505, 1504],\n",
    "    'J53_TMT_B_P1': [1505, 1505, 1505],\n",
    "    'J53_TMT_B_P2': [1505, 1505, 1505],\n",
    "    'J54_PNT_B_P1': [1505, 1505, 1505], #\n",
    "    'J54_PNT_B_P2': [1505, 1505, 1505], #\n",
    "    'J55_TMT_B_P1': [1505, 1505, 1505],\n",
    "    'J31_PNT_B_P1': [1505, 1505, 1505],\n",
    "    'J50_PNT_B_P1': [1505, 1505, 1505],\n",
    "    'J51_PNT_B_P1': [1505, 1505, 1505],\n",
    "    'J51_PNT_B_P2': [1505, 1505, 1505],\n",
    "    'J52_PNT_B_P1': [1505, 1505, 1505],\n",
    "    'J52_PNT_B_P2': [1505, 1505, 1505],\n",
    "    'J53_PNT_A_P1': [1505, 1505, 1505],\n",
    "    'J53_PNT_A_P2': [1505, 1505, 1504],\n",
    "    'J54_PNT_A_P1': [1505, 1505, 1505], #\n",
    "    'J54_PNT_A_P2': [1505, 1505, 1505], #\n",
    "    'J55_PNT_A_P1': [1505, 1505, 1505],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:07:02.782260Z",
     "start_time": "2017-11-05T17:06:43.155449Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "ca_import = {\n",
    "    tuple(os.path.splitext(os.path.basename(f))[0].split('_')): np.loadtxt(f, delimiter=',')\n",
    "    for f in ca_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T17:09:13.003162Z",
     "start_time": "2017-11-05T17:09:12.362874Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe for calcium traces\n",
    "\n",
    "# Create new dictionary with key for each neuron\n",
    "ca_data = {}\n",
    "for exp, exp_data in ca_import.iteritems():\n",
    "    n_cells, n_frames = exp_data.shape\n",
    "    exp_id = frame_ct['_'.join(exp[1:])]\n",
    "    \n",
    "    epoch_split = np.split(exp_data, np.cumsum(exp_id)[:2], axis=1)\n",
    "    epoch_split_new = [\n",
    "        np.concatenate([epoch, np.nan * np.zeros((n_cells, frames_per_epoch - nf))], axis=1)\n",
    "        for epoch, nf in zip(epoch_split, exp_id)\n",
    "    ]\n",
    "    traces_new = np.concatenate(epoch_split_new, axis=1)\n",
    "    \n",
    "    for n, cell_data in enumerate(traces_new):\n",
    "        ca_data[exp + (n, )] = cell_data\n",
    "\n",
    "# Create dataframe\n",
    "neural_df = pd.DataFrame(ca_data)\n",
    "\n",
    "# Format columns\n",
    "col_names = ['data type', 'subject', 'experiment', 'order', 'plane', 'neuron']\n",
    "col_order = ['data type', 'experiment', 'subject', 'plane', 'order', 'neuron']\n",
    "neural_df.columns.names = col_names\n",
    "neural_df = neural_df.reorder_levels(col_order, axis=1)\n",
    "neural_df = neural_df.sort_index(axis=1)\n",
    "\n",
    "# Format index\n",
    "neural_df.index = pd.MultiIndex.from_product(\n",
    "    [['base', 'h2o', 'odor'], np.arange(frames_per_epoch) * frame_period],\n",
    "    names=['epoch', 'time']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:21.248370Z",
     "start_time": "2017-11-04T19:45:20.941730Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "\n",
    "delete_import = pd.concat(\n",
    "    [pd.read_csv(del_pnt, delimiter=','), pd.read_csv(del_tmt, delimiter=',')],\n",
    "    axis=1, keys=['PNT', 'TMT']\n",
    ")\n",
    "delete_import.columns = pd.MultiIndex.from_tuples(\n",
    "    [[x[0], ] + x[1].split('_') for x in delete_import.columns]\n",
    ")\n",
    "\n",
    "# Cells to delete from TMT dataset\n",
    "to_delete = [\n",
    "    col + (int(x) - 1, )\n",
    "    for col in delete_import for x in delete_import[col]\n",
    "    if not np.isnan(x)\n",
    "]\n",
    "\n",
    "temp = neural_df.T.reset_index(['data type', 'order']).T\n",
    "temp = temp.drop(to_delete, axis=1)\n",
    "temp = temp.T.set_index(['data type', 'order'], append=True).T\n",
    "temp = temp.reorder_levels(col_order, axis=1)\n",
    "temp = temp.sort_index(axis=1)\n",
    "neural_df = temp.dropna(axis=0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make sure this works with spiking data also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:21.565240Z",
     "start_time": "2017-11-04T19:45:21.250248Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_match_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-839405bc5f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Iterate over experiments, choosing only cells in peanut oil ones. Assign number based on match file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatch_import\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf_match_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmatch_import\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# start indexing at 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m match_import.columns = pd.MultiIndex.from_tuples(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_match_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Match cells\n",
    "# Iterate over experiments, choosing only cells in peanut oil ones. Assign number based on match file.\n",
    "\n",
    "match_import = pd.read_csv(hf_match_file, delimiter=',', header=0)\n",
    "match_import -= 1  # start indexing at 0\n",
    "match_import.columns = pd.MultiIndex.from_tuples(\n",
    "    [[x.split('_')[0], x.split('_')[1]] for x in match_import.columns],\n",
    "    names=['subject', 'plane']\n",
    ")\n",
    "\n",
    "neural_df_new = []  # new dataframe with updated matched cell labelling\n",
    "for grp, grp_df in neural_df.groupby(level=['subject', 'plane'], axis=1):\n",
    "    try:\n",
    "        n_tmt_cells = max([x[-1] for x in grp_df.xs('TMT', axis=1, level='experiment')]) + 1\n",
    "        print grp, n_tmt_cells\n",
    "    except ValueError:\n",
    "        print('No TMT experiments found for {}'.format(grp))\n",
    "        continue\n",
    "    key = match_import[grp]\n",
    "\n",
    "    col = grp_df.columns.tolist()\n",
    "    for n, x in enumerate(col):\n",
    "        if 'PNT' in x:\n",
    "            neuron_id = x[-1]\n",
    "            matched_cell = key[neuron_id]\n",
    "            if not np.isnan(matched_cell):\n",
    "                col[n] = x[:-1] + (int(matched_cell), )\n",
    "            else:\n",
    "                col[n] = x[:-1] + (x[-1] + n_tmt_cells, )\n",
    "\n",
    "    grp_df.columns = pd.MultiIndex.from_tuples(col, names=grp_df.columns.names)\n",
    "    neural_df_new.append(grp_df)\n",
    "\n",
    "neural_df_matched = pd.concat(neural_df_new, axis=1).sort_index(axis=1)\n",
    "\n",
    "# # Following doesn't work...\n",
    "# def match_cells(paired_df):\n",
    "#     ''' Rename cells based on match from CSV file\n",
    "#     Doesn't work because `groupby` won't change column names on original dataframe... -_-\n",
    "#     '''\n",
    "#     n_tmt_cells = max([x[-1] for x in paired_df.xs('TMT', axis=1, level='odor')]) + 1\n",
    "#     key = match_import[paired_df.columns[0][2:4]]\n",
    "\n",
    "#     col = paired_df.columns.tolist()\n",
    "#     for n, x in enumerate(col):\n",
    "#         if 'PNT' in x:\n",
    "#             neuron_id = x[-1]\n",
    "#             if not np.isnan(key[neuron_id]):\n",
    "#                 col[n] = x[:-1] + (int(key[neuron_id]), )\n",
    "#             else:\n",
    "#                 col[n] = x[:-1] + (x[-1] + n_tmt_cells, )\n",
    "\n",
    "#     paired_df.columns = pd.MultiIndex.from_tuples(col, names=paired_df.columns.names)\n",
    "#     return paired_df\n",
    "\n",
    "# neural_df = neural_df.groupby(level=['subject', 'plane'], axis=1).apply(match_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:45:21.710265Z",
     "start_time": "2017-11-04T19:45:21.566832Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rung/anaconda3/envs/py2/lib/python2.7/site-packages/pandas/io/pytables.py:486: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis1_level1] [items->None]\n",
      "\n",
      "  self.put(key, value)\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(h5_out) as hf:\n",
    "#     hf['neural'] = neural_df_matched\n",
    "    hf['neural'] = neural_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "228px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "739px",
    "left": "0px",
    "right": "1317px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
